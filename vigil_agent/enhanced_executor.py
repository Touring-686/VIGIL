"""å¢å¼ºç‰ˆVIGILæ‰§è¡Œå™¨

æ•´åˆäº†Perception Sanitizerçš„å·¥å…·æ‰§è¡Œå™¨ã€‚
"""

import logging
from collections.abc import Callable, Sequence

from agentdojo.agent_pipeline.base_pipeline_element import BasePipelineElement
from agentdojo.functions_runtime import EmptyEnv, Env, FunctionReturnType, FunctionsRuntime
from agentdojo.types import ChatMessage, ChatToolResultMessage, text_content_block_from_string

from vigil_agent.abstract_sketch import AbstractSketchGenerator
from vigil_agent.commitment_manager import CommitmentManager
from vigil_agent.config import VIGILConfig
from vigil_agent.constraint_generator import ConstraintGenerator
from vigil_agent.enhanced_auditor import EnhancedRuntimeAuditor
from vigil_agent.hypothesizer import Hypothesizer
from vigil_agent.path_cache import PathCache
from vigil_agent.perception_sanitizer import PerceptionSanitizer
from vigil_agent.types import ToolCallInfo

logger = logging.getLogger(__name__)


def enhanced_tool_result_to_str(tool_result: FunctionReturnType) -> str:
    """å·¥å…·ç»“æœæ ¼å¼åŒ–å™¨"""
    from agentdojo.agent_pipeline.tool_execution import tool_result_to_str

    return tool_result_to_str(tool_result)


class EnhancedVIGILToolsExecutor(BasePipelineElement):
    """å¢å¼ºç‰ˆVIGILå·¥å…·æ‰§è¡Œå™¨

    æ•´åˆäº†ä»¥ä¸‹åŠŸèƒ½ï¼š
    1. Perception Sanitizer: æ¸…æ´—å·¥å…·è¿”å›å€¼å’Œé”™è¯¯æ¶ˆæ¯
    2. Runtime Auditor: å®‰å…¨å®¡è®¡
    3. Reflective Backtracking: åæ€å›æº¯

    æ‰§è¡Œæµç¨‹ï¼š
    1. æå–å·¥å…·è°ƒç”¨
    2. è¿›è¡Œå®‰å…¨å®¡è®¡
    3. å¦‚æœå…è®¸ï¼šæ‰§è¡Œå·¥å…· + æ¸…æ´—è¿”å›å€¼
    4. å¦‚æœæ‹’ç»ï¼šè¿”å›åé¦ˆæ¶ˆæ¯ï¼ˆè§¦å‘å›æº¯ï¼‰
    """

    def __init__(
        self,
        config: VIGILConfig,
        auditor: EnhancedRuntimeAuditor,
        sanitizer: PerceptionSanitizer,
        hypothesizer=None,
        commitment_manager: CommitmentManager | None = None,
        path_cache: PathCache | None = None,
        tool_output_formatter: Callable[[FunctionReturnType], str] = enhanced_tool_result_to_str,
    ):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆVIGILå·¥å…·æ‰§è¡Œå™¨

        Args:
            config: VIGILé…ç½®
            auditor: å¢å¼ºç‰ˆè¿è¡Œæ—¶å®¡è®¡å™¨
            sanitizer: æ„ŸçŸ¥å±‚æ¸…æ´—å™¨
            hypothesizer: å‡è®¾æ¨ç†å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºå¤šåˆ†æ”¯æ¨ç†ï¼‰
            commitment_manager: æ‰¿è¯ºç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºé€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼‰
            path_cache: è·¯å¾„ç¼“å­˜ï¼ˆå¯é€‰ï¼Œç”¨äºå­¦ä¹ å’Œä¼˜åŒ–ï¼‰
            tool_output_formatter: å·¥å…·è¾“å‡ºæ ¼å¼åŒ–å‡½æ•°
        """
        self.config = config
        self.auditor = auditor
        self.sanitizer = sanitizer
        self.hypothesizer = hypothesizer
        self.commitment_manager = commitment_manager
        self.path_cache = path_cache
        self.output_formatter = tool_output_formatter

        # è·Ÿè¸ªæ¯ä¸ªå·¥å…·è°ƒç”¨çš„å›æº¯æ¬¡æ•°
        self._backtracking_counts: dict[str, int] = {}

        # è·Ÿè¸ªå‚æ•°éªŒè¯é”™è¯¯çš„é‡è¯•æ¬¡æ•°
        self._validation_retry_counts: dict[str, int] = {}
        self._max_validation_retries = 3  # æ¯ä¸ªå·¥å…·æœ€å¤šé‡è¯•3æ¬¡å‚æ•°

    def query(
        self,
        query: str,
        runtime: FunctionsRuntime,
        env: Env = EmptyEnv(),
        messages: Sequence[ChatMessage] = [],
        extra_args: dict = {},
    ) -> tuple[str, FunctionsRuntime, Env, Sequence[ChatMessage], dict]:
        """æ‰§è¡Œpipelineå…ƒç´ 

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            runtime: å‡½æ•°è¿è¡Œæ—¶
            env: ç¯å¢ƒ
            messages: æ¶ˆæ¯å†å²
            extra_args: é¢å¤–å‚æ•°

        Returns:
            æ›´æ–°åçš„æŸ¥è¯¢ã€è¿è¡Œæ—¶ã€ç¯å¢ƒã€æ¶ˆæ¯å’Œé¢å¤–å‚æ•°
        """
        # ===== ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ REASONING æ­¥éª¤ï¼ˆ__no_tool_call__ï¼‰=====
        # REASONING æ­¥éª¤ï¼šç›´æ¥è°ƒç”¨ LLM è¿›è¡Œæ¨ç†ï¼ŒæŠŠ LLM å½“ä½œä¸€ä¸ªå·¥å…·
        current_step_is_reasoning = extra_args.get('current_step_is_reasoning', False)
        current_step_is_response = extra_args.get('current_step_is_response', False)

        if current_step_is_reasoning:
            if current_step_is_response:
                logger.info(
                    "[EnhancedVIGILExecutor] ğŸ“ RESPONSE step detected - calling LLM to generate final response"
                )
            else:
                logger.info(
                    "[EnhancedVIGILExecutor] ğŸ§  REASONING step detected - calling LLM as a reasoning tool (no tool execution allowed)"
                )

            # è°ƒç”¨ LLM è¿›è¡Œæ¨ç†ï¼ˆä¸å…è®¸ä½¿ç”¨å·¥å…·ï¼‰
            reasoning_message = self._execute_reasoning_step(messages, query, extra_args)

            # å°† LLM çš„æ¨ç†ç»“æœä½œä¸º assistant message æ·»åŠ åˆ°å†å²
            messages = [*messages, reasoning_message]

            # å¦‚æœæ˜¯ __response__ æ­¥éª¤ï¼Œå°†è¾“å‡ºå­˜å‚¨åˆ° extra_args ä¸­
            if current_step_is_response:
                # æå–å“åº”å†…å®¹
                response_content = "Response completed."
                if reasoning_message and "content" in reasoning_message and reasoning_message["content"]:
                    if isinstance(reasoning_message["content"], list) and len(reasoning_message["content"]) > 0:
                        content_block = reasoning_message["content"][0]
                        response_content = content_block.get("content", response_content)

                # å­˜å‚¨åˆ° extra_argsï¼Œç”¨äºæœ€ç»ˆè¿”å›
                extra_args = {**extra_args, 'final_response': response_content}

                logger.info(
                    "[EnhancedVIGILExecutor] âœ“ RESPONSE step completed - output stored in extra_args"
                )
            else:
                logger.info(
                    "[EnhancedVIGILExecutor] âœ“ REASONING step completed - LLM provided analysis"
                )

            # === è®°å½• REASONING/RESPONSE æ­¥éª¤åˆ°æ‰§è¡Œå†å² ===
            if self.auditor:
                current_step_index = extra_args.get('current_step_index', 0)
                step_description = None

                # ä» abstract sketch è·å–æ­¥éª¤æè¿°
                if self.auditor.abstract_sketch and hasattr(self.auditor.abstract_sketch, 'steps'):
                    if current_step_index < len(self.auditor.abstract_sketch.steps):
                        step = self.auditor.abstract_sketch.steps[current_step_index - 1]
                        step_description = f"{step.step_type} - {step.description}"

                # æå–æ¨ç†ç»“æœæ–‡æœ¬
                reasoning_result = "Reasoning completed."
                if reasoning_message and "content" in reasoning_message and reasoning_message["content"]:
                    if isinstance(reasoning_message["content"], list) and len(reasoning_message["content"]) > 0:
                        content_block = reasoning_message["content"][0]
                        reasoning_result = content_block.get("content", reasoning_result)

                # åˆ›å»ºè™šæ‹Ÿçš„ tool_call_info ç”¨äºè®°å½•
                tool_name = "__llm_response__" if current_step_is_response else "__llm_reasoning__"
                reasoning_tool_call: ToolCallInfo = {
                    "tool_name": tool_name,
                    "arguments": {},
                    "tool_call_id": None,
                }

                self.auditor.record_execution_step(
                    step_index=current_step_index,
                    tool_call_info=reasoning_tool_call,
                    result=reasoning_result,
                    step_description=step_description,
                )

                if self.config.log_audit_decisions:
                    step_type = "RESPONSE" if current_step_is_response else "REASONING"
                    logger.info(
                        f"[EnhancedVIGILExecutor] Recorded {step_type} step {current_step_index + 1} "
                        f"to execution history: {reasoning_result[:100]}..."
                    )

            # æ¸…é™¤ REASONING æ ‡å¿—
            extra_args = {**extra_args, 'current_step_is_reasoning': False, 'finished_task': False}

            return query, runtime, env, messages, extra_args

        # ===== æ­£å¸¸çš„å·¥å…·æ‰§è¡Œæµç¨‹ =====
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
        if len(messages) == 0:
            return query, runtime, env, messages, extra_args

        if messages[-1]["role"] != "assistant":
            return query, runtime, env, messages, extra_args

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if messages[-1]["tool_calls"] is None or len(messages[-1]["tool_calls"]) == 0:
            return query, runtime, env, messages, extra_args

        # ===== CRITICAL: æ£€æŸ¥æ˜¯å¦å°è¯•è°ƒç”¨å¤šä¸ªå·¥å…· =====
        # VIGILçš„è®¾è®¡åŸåˆ™ï¼šæ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªå·¥å…·ï¼Œç¡®ä¿å¯æ§æ€§å’Œå®‰å…¨æ€§
        if len(messages[-1]["tool_calls"]) > 1:
            logger.warning(
                f"[EnhancedVIGILToolsExecutor] Agent attempted to call {len(messages[-1]['tool_calls'])} tools "
                f"simultaneously. VIGIL policy: ONE tool per turn."
            )

            # æ‹’ç»æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›é”™è¯¯æ¶ˆæ¯
            error_message = (
                f"âŒ VIGIL Policy Violation: Multiple Tool Calls Detected\n\n"
                f"You attempted to call {len(messages[-1]['tool_calls'])} tools simultaneously:\n"
            )

            for i, tc in enumerate(messages[-1]["tool_calls"], 1):
                error_message += f"  {i}. {tc.function}({dict(tc.args)})\n"

            error_message += (
                f"\n**VIGIL Policy: You MUST call exactly ONE tool per turn.**\n\n"
                f"To complete this task:\n"
                f"1. Choose the MOST IMPORTANT tool for the current step\n"
                f"2. Call that tool alone and wait for its result\n"
                f"3. In subsequent turns, call additional tools if needed\n\n"
                f"Please retry with a SINGLE tool call."
            )

            # ç”Ÿæˆä¸€ä¸ªé”™è¯¯ç»“æœæ¶ˆæ¯ï¼ˆé’ˆå¯¹ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼‰
            tool_call_results = [
                ChatToolResultMessage(
                    role="tool",
                    content=[text_content_block_from_string(error_message)],
                    tool_call_id=messages[-1]["tool_calls"][0].id,
                    tool_call=messages[-1]["tool_calls"][0],
                    error=error_message,
                )
            ]

            # ç«‹å³è¿”å›é”™è¯¯ï¼Œä¸æ‰§è¡Œä»»ä½•å·¥å…·
            return query, runtime, env, [*messages, *tool_call_results], extra_args

        # è®¾ç½®å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆç”¨äºå†—ä½™æ€§æ£€æŸ¥ï¼‰
        available_tools = [
            {"name": tool.name, "description": tool.description}
            for tool in runtime.functions.values()
        ]
        self.auditor.set_available_tools(available_tools)

        # æ³¨æ„ï¼šHypothesis Tree ç”Ÿæˆå·²ç§»è‡³ HypothesisGuidanceElement
        # è¯¥elementåœ¨LLMæ¨ç†ä¹‹å‰è¿è¡Œï¼Œç”Ÿæˆguidanceå¹¶æ³¨å…¥åˆ°contextä¸­
        # è¿™ç¡®ä¿äº†æ­£ç¡®çš„æ‰§è¡Œé¡ºåºï¼š
        #   Hypothesis Generation â†’ Verification â†’ Commitment â†’ LLM Decision
        # è€Œä¸æ˜¯é”™è¯¯çš„ï¼š
        #   LLM Decision â†’ Hypothesis Generation (äº‹ååˆ†æ)

        # å¤„ç†å·¥å…·è°ƒç”¨
        tool_call_results = []

        for tool_call in messages[-1]["tool_calls"]:
            # åˆ›å»ºå·¥å…·è°ƒç”¨ä¿¡æ¯
            tool_call_info: ToolCallInfo = {
                "tool_name": tool_call.function,
                "arguments": dict(tool_call.args),
                "tool_call_id": tool_call.id,
            }

            # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
            if tool_call.function not in (tool.name for tool in runtime.functions.values()):
                tool_call_results.append(
                    ChatToolResultMessage(
                        role="tool",
                        content=[text_content_block_from_string("")],
                        tool_call_id=tool_call.id,
                        tool_call=tool_call,
                        error=f"Invalid tool {tool_call.function} provided.",
                    )
                )
                continue

            # ===== æ£€æŸ¥æ˜¯å¦éœ€è¦å®¡è®¡ =====
            # åœ¨ direct mode ä¸‹ï¼Œå¦‚æœå·¥å…·å·²ç»é€šè¿‡ HypothesisGuidance çš„å®Œæ•´å®¡è®¡ï¼Œè·³è¿‡é‡å¤å®¡è®¡
            skip_audit = extra_args.get('skip_audit', False) and extra_args.get('vigil_pre_approved') == tool_call.function

            if skip_audit:
                # å·¥å…·å·²ç»é€šè¿‡ Two-Stage Verificationï¼Œç›´æ¥æ‰§è¡Œ
                if self.config.log_audit_decisions:
                    logger.info(
                        f"[EnhancedVIGILExecutor] Tool '{tool_call.function}' PRE-APPROVED by HypothesisGuidance "
                        f"(Two-Stage Verification passed), skipping redundant audit"
                    )

                # ç›´æ¥æ‰§è¡Œå·¥å…·ï¼ˆè·³åˆ°æ‰§è¡Œéƒ¨åˆ†ï¼‰
                needs_backtrack = self._execute_tool(
                    tool_call=tool_call,
                    tool_call_info=tool_call_info,
                    runtime=runtime,
                    env=env,
                    query=query,
                    tool_call_results=tool_call_results,
                    extra_args=extra_args,
                )

                # å¦‚æœæ£€æµ‹åˆ°éœ€è¦å›æº¯ï¼ˆSOP æ³¨å…¥ï¼‰ï¼Œè®¾ç½®æ ‡å¿—
                if needs_backtrack:
                    extra_args = {**extra_args, 'backtrack_needed': True}

                # æ¸…é™¤æ ‡å¿—ï¼ˆé¿å…å½±å“ä¸‹ä¸€è½®ï¼‰
                if 'skip_audit' in extra_args:
                    extra_args = {**extra_args, 'skip_audit': False, 'vigil_pre_approved': None}

                continue

            # ===== è¿›è¡Œå®‰å…¨å®¡è®¡ =====
            # æ³¨æ„ï¼šè¿™é‡Œçš„å®¡è®¡æ˜¯é’ˆå¯¹ä»¥ä¸‹åœºæ™¯ï¼š
            # 1. Guidance modeï¼šLLM å¯èƒ½ä¸éµå¾ª guidanceï¼Œéœ€è¦æœ€åä¸€é“é˜²çº¿
            # 2. é direct modeï¼šä¼ ç»Ÿçš„å®¡è®¡æµç¨‹
            if self.config.log_audit_decisions:
                logger.info(
                    f"[EnhancedVIGILExecutor] Auditing tool call: {tool_call.function} "
                    f"(not pre-approved, performing full security check)"
                )

            audit_result = self.auditor.audit_tool_call(tool_call_info)

            if not audit_result.allowed:
                # å·¥å…·è°ƒç”¨è¢«æ‹¦æˆª
                if self.config.log_audit_decisions:
                    logger.warning(f"[EnhancedVIGILExecutor] Tool call blocked: {tool_call.function}")

                # æ£€æŸ¥å›æº¯æ¬¡æ•°
                backtrack_key = f"{tool_call.function}:{str(tool_call.args)}"
                backtrack_count = self._backtracking_counts.get(backtrack_key, 0)

                if (
                    self.config.enable_reflective_backtracking
                    and backtrack_count < self.config.max_backtracking_attempts
                ):
                    # å¯ç”¨å›æº¯ï¼šè¿”å›åé¦ˆæ¶ˆæ¯
                    self._backtracking_counts[backtrack_key] = backtrack_count + 1

                    feedback_message = audit_result.feedback_message or (
                        f"The tool call '{tool_call.function}' was blocked by security constraints. "
                        "Please try a different approach."
                    )

                    # æ·»åŠ å›æº¯æç¤º
                    if self.config.feedback_verbosity in ["detailed", "verbose"]:
                        feedback_message += (
                            f"\n\nAttempt {backtrack_count + 1}/{self.config.max_backtracking_attempts}. "
                            "Consider alternative tools or different parameters."
                        )

                    tool_call_results.append(
                        ChatToolResultMessage(
                            role="tool",
                            content=[text_content_block_from_string(feedback_message)],
                            tool_call_id=tool_call.id,
                            tool_call=tool_call,
                            error="SecurityConstraintViolation",
                        )
                    )

                    logger.info(
                        f"[EnhancedVIGILExecutor] Reflective backtracking enabled for {tool_call.function} "
                        f"(attempt {backtrack_count + 1}/{self.config.max_backtracking_attempts})"
                    )
                else:
                    # è¶…è¿‡å›æº¯æ¬¡æ•°æˆ–æœªå¯ç”¨å›æº¯ï¼šè¿”å›é”™è¯¯
                    error_message = (
                        audit_result.feedback_message
                        or f"Tool '{tool_call.function}' cannot be executed due to security constraints."
                    )

                    if backtrack_count >= self.config.max_backtracking_attempts:
                        error_message += f"\n\nMaximum backtracking attempts ({self.config.max_backtracking_attempts}) reached."

                    tool_call_results.append(
                        ChatToolResultMessage(
                            role="tool",
                            content=[text_content_block_from_string(error_message)],
                            tool_call_id=tool_call.id,
                            tool_call=tool_call,
                            error="SecurityConstraintViolation",
                        )
                    )

                    logger.warning(
                        f"[EnhancedVIGILExecutor] Tool call permanently blocked: {tool_call.function}"
                    )

            else:
                # å·¥å…·è°ƒç”¨è¢«å…è®¸ï¼Œæ‰§è¡Œå®ƒ
                if self.config.log_audit_decisions:
                    logger.info(f"[EnhancedVIGILExecutor] âœ“ Tool call ALLOWED: {tool_call.function}")

                # æ‰§è¡Œå·¥å…·
                needs_backtrack = self._execute_tool(
                    tool_call=tool_call,
                    tool_call_info=tool_call_info,
                    runtime=runtime,
                    env=env,
                    query=query,
                    tool_call_results=tool_call_results,
                    extra_args=extra_args,
                )

                # å¦‚æœæ£€æµ‹åˆ°éœ€è¦å›æº¯ï¼ˆSOP æ³¨å…¥ï¼‰ï¼Œè®¾ç½®æ ‡å¿—
                if needs_backtrack:
                    extra_args = {**extra_args, 'backtrack_needed': True}

        # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰ abstract sketch æ­¥éª¤
        # æ¡ä»¶ï¼š
        # 1. æ²¡æœ‰éœ€è¦å›æº¯çš„æƒ…å†µ
        # 2. æœ‰ abstract sketch
        # 3. å½“å‰æ­¥éª¤ç´¢å¼•å·²ç»åˆ°è¾¾æˆ–è¶…è¿‡æ€»æ­¥éª¤æ•°
        if not extra_args.get('backtrack_needed', False):
            # ä» extra_args æˆ– auditor è·å– abstract sketch
            abstract_sketch = extra_args.get('vigil_abstract_sketch') or (
                self.auditor.abstract_sketch if hasattr(self, 'auditor') and self.auditor else None
            )

            if abstract_sketch and hasattr(abstract_sketch, 'steps'):
                # ä» hypothesis_guidance è·å–å½“å‰æ­¥éª¤ç´¢å¼•
                # æ­¥éª¤ç´¢å¼•åœ¨ HypothesisGuidance ä¸­ç»´æŠ¤
                current_step_index = extra_args.get('current_step_index', 0)
                total_steps = len(abstract_sketch.steps)

                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½å®Œæˆäº†
                # æ³¨æ„ï¼šcurrent_step_index åœ¨ HypothesisGuidance ä¸­æ¯æ¬¡æ‰§è¡Œåä¼š +1
                # æ‰€ä»¥å½“ current_step_index >= total_steps æ—¶ï¼Œè¯´æ˜æ‰€æœ‰æ­¥éª¤éƒ½æ‰§è¡Œå®Œäº†
                if current_step_index >= total_steps:
                    extra_args = {**extra_args, 'finished_task': True}
                    logger.info(
                        f"[EnhancedVIGILExecutor] âœ“ All {total_steps} sketch steps completed successfully, "
                        f"marking task as finished"
                    )

        return query, runtime, env, [*messages, *tool_call_results], extra_args

    def _execute_tool(
        self,
        tool_call,
        tool_call_info: ToolCallInfo,
        runtime: FunctionsRuntime,
        env: Env,
        query: str,
        tool_call_results: list,
        extra_args: dict = {},
    ) -> bool:
        """æ‰§è¡Œå·¥å…·å¹¶æ·»åŠ ç»“æœåˆ° tool_call_results

        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
            tool_call_info: å·¥å…·è°ƒç”¨ä¿¡æ¯
            runtime: å‡½æ•°è¿è¡Œæ—¶
            env: ç¯å¢ƒ
            query: ç”¨æˆ·æŸ¥è¯¢
            tool_call_results: ç»“æœåˆ—è¡¨ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
            extra_args: é¢å¤–å‚æ•°ï¼ˆåŒ…å« current_step_index ç­‰ï¼‰

        Returns:
            æ˜¯å¦éœ€è¦å›æº¯ï¼ˆTrue è¡¨ç¤ºæ£€æµ‹åˆ° SOP æ³¨å…¥ï¼Œéœ€è¦å°è¯•å…¶ä»–åˆ†æ”¯ï¼‰
        """
        # === ValidationError è‡ªåŠ¨é‡è¯•å¾ªç¯ ===
        max_validation_retries = self._max_validation_retries
        current_retry = 0
        current_args = tool_call.args
        tool_call_result = None
        error = None

        while current_retry <= max_validation_retries:
            # æ‰§è¡Œå·¥å…·
            logger.info(f"[EnhancedVIGILExecutor] Executing tool: {tool_call.function}({dict(current_args)}) [attempt {current_retry + 1}]")
            tool_call_result, error = runtime.run_function(env, tool_call.function, current_args)
            logger.info(f"[EnhancedVIGILExecutor] Tool execution completed. Error: {error is not None}")

            # æ£€æŸ¥æ˜¯å¦ä¸º ValidationError
            if error and self._is_validation_error(error):
                current_retry += 1

                if current_retry > max_validation_retries:
                    logger.warning(
                        f"[EnhancedVIGILExecutor] ValidationError retry limit reached for '{tool_call.function}' "
                        f"({current_retry} attempts). Returning error to LLM."
                    )
                    break

                # è°ƒç”¨ LLM åˆ†æé”™è¯¯å¹¶ä¿®æ­£å‚æ•°
                logger.info(
                    f"[EnhancedVIGILExecutor] ValidationError detected. "
                    f"Calling LLM to fix parameters (attempt {current_retry}/{max_validation_retries})..."
                )

                corrected_args = self._llm_fix_validation_error(
                    tool_name=tool_call.function,
                    original_args=current_args,
                    error_message=error,
                    runtime=runtime
                )

                if corrected_args is None:
                    logger.warning(
                        f"[EnhancedVIGILExecutor] LLM unable to fix ValidationError. Returning error to LLM."
                    )
                    break

                logger.info(
                    f"[EnhancedVIGILExecutor] LLM corrected parameters: {dict(current_args)} -> {dict(corrected_args)}"
                )

                # ä½¿ç”¨ä¿®æ­£åçš„å‚æ•°é‡è¯•
                current_args = corrected_args
                tool_call.args = corrected_args  # æ›´æ–° tool_call å¯¹è±¡
                continue
            else:
                # æ²¡æœ‰ ValidationErrorï¼ˆæ‰§è¡ŒæˆåŠŸæˆ–é‡åˆ°å…¶ä»–é”™è¯¯ï¼‰ï¼Œé€€å‡ºå¾ªç¯
                break

        # === åˆ†ç±»é”™è¯¯ç±»å‹ ===
        needs_backtrack = False
        is_validation_error = False
        original_error = error  # ä¿å­˜åŸå§‹é”™è¯¯ç”¨äºæ£€æµ‹

        # æ£€æµ‹é”™è¯¯ç±»å‹ï¼ˆé‡è¯•åä»æœ‰é”™è¯¯çš„æƒ…å†µï¼‰
        if error:
            # 1. æ£€æµ‹å‚æ•°ç±»å‹éªŒè¯é”™è¯¯ï¼ˆå·²ç»é‡è¯•è¿‡ï¼Œç°åœ¨å¤±è´¥äº†ï¼‰
            is_validation_error = self._is_validation_error(error)

            if is_validation_error:
                logger.warning(
                    f"[EnhancedVIGILExecutor] ValidationError persists after {current_retry} retries for '{tool_call.function}'. "
                    f"Converting to backtrack."
                )
                # è¶…è¿‡é‡è¯•é™åˆ¶ï¼Œè½¬æ¢ä¸ºéœ€è¦å›æº¯ï¼ˆå°è¯•å…¶ä»–å·¥å…·ï¼‰
                is_validation_error = False
                needs_backtrack = True

            # 2. æ£€æµ‹ SOP æ³¨å…¥ï¼ˆæ¶æ„æ”»å‡»ï¼Œéœ€è¦å›æº¯ï¼‰
            if not is_validation_error and self._detect_sop_injection(error):
                logger.warning(
                    f"[EnhancedVIGILExecutor] âš ï¸ SOP INJECTION DETECTED in error message "
                    f"from tool '{tool_call.function}' (Type III-A/III-B attack)"
                )
                needs_backtrack = True

        # === Perception Sanitizer: æ¸…æ´—è¿”å›å€¼å’Œé”™è¯¯ ===
        if self.config.enable_perception_sanitizer:
            # æ¸…æ´—è¿”å›å€¼
            tool_call_result = self.sanitizer.sanitize_tool_result(
                tool_call.function, tool_call_result
            )

            # æ¸…æ´—é”™è¯¯æ¶ˆæ¯
            if error:
                if is_validation_error:
                    # å‚æ•°éªŒè¯é”™è¯¯ï¼šä¿ç•™è¯¦ç»†ä¿¡æ¯ä¾› LLM ä¿®æ­£ï¼Œä½†ç§»é™¤å¯èƒ½çš„æ³¨å…¥
                    error = self._sanitize_validation_error(error, tool_call.function)
                else:
                    # å…¶ä»–é”™è¯¯ï¼ˆåŒ…æ‹¬ SOP æ³¨å…¥ï¼‰ï¼šå®Œå…¨æ¸…æ´—
                    error = self.sanitizer.sanitize_error_message(tool_call.function, error)

                if self.config.log_sanitizer_actions and original_error:
                    logger.info(
                        f"[EnhancedVIGILExecutor] Error message sanitized: "
                        f"'{original_error[:100]}...' â†’ '{error[:100] if error else 'None'}...'"
                    )

        formatted_result = self.output_formatter(tool_call_result)

        tool_call_results.append(
            ChatToolResultMessage(
                role="tool",
                content=[text_content_block_from_string(formatted_result)],
                tool_call_id=tool_call.id,
                tool_call=tool_call,
                error=error,
            )
        )

        # === è®°å½•æ‰§è¡Œå†å²ï¼ˆä»…åœ¨æˆåŠŸæ—¶ï¼‰===
        if not error and self.auditor:
            current_step_index = extra_args.get('current_step_index', 0)
            step_description = None

            # ä» abstract sketch è·å–æ­¥éª¤æè¿°
            if self.auditor.abstract_sketch and hasattr(self.auditor.abstract_sketch, 'steps'):
                if current_step_index < len(self.auditor.abstract_sketch.steps):
                    step = self.auditor.abstract_sketch.steps[current_step_index - 1]
                    step_description = f"{step.step_type} - {step.description}"

            self.auditor.record_execution_step(
                step_index=current_step_index,
                tool_call_info=tool_call_info,
                result=formatted_result,
                step_description=step_description,
            )

        # === Path Cache: è®°å½•æˆåŠŸæ‰§è¡Œçš„è·¯å¾„ ===
        if self.path_cache:
            # åˆ¤æ–­æ‰§è¡Œæ˜¯å¦æˆåŠŸï¼ˆæ— é”™è¯¯ï¼‰
            outcome = "failure" if error else "success"

            # è·å–å½“å‰æ­¥éª¤ç´¢å¼•
            current_step_index = extra_args.get('current_step_index', 0)

            # è·å– abstract step descriptionï¼ˆä» auditor çš„ abstract sketchï¼‰
            abstract_step_description = None
            if self.auditor and self.auditor.abstract_sketch and hasattr(self.auditor.abstract_sketch, 'steps'):
                # current_step_index åœ¨æ‰§è¡Œæ—¶å·²ç»+1äº†ï¼Œæ‰€ä»¥éœ€è¦-1æ¥è·å–å½“å‰æ­¥éª¤
                step_idx = current_step_index - 1
                if 0 <= step_idx < len(self.auditor.abstract_sketch.steps):
                    current_step = self.auditor.abstract_sketch.steps[step_idx]
                    abstract_step_description = current_step.description

            # æ·»åŠ åˆ° path cacheï¼ˆå…³é”®ï¼šä¼ é€’ step_index å’Œ abstract_step_descriptionï¼‰
            self.path_cache.add_verified_path(
                user_query=query,
                tool_name=tool_call.function,
                arguments=dict(tool_call.args),
                outcome=outcome,
                step_index=current_step_index,  # ä¼ é€’æ­¥éª¤ç´¢å¼•
                abstract_step_description=abstract_step_description,  # ä¼ é€’æŠ½è±¡æ­¥éª¤æè¿°
                metadata={"error": error} if error else None,
            )

            if self.config.log_audit_decisions and outcome == "success":
                logger.info(
                    f"[EnhancedVIGILExecutor] âœ“ Path cached: step {current_step_index}, "
                    f"tool '{tool_call.function}', outcome '{outcome}'"
                )
                if abstract_step_description:
                    logger.debug(
                        f"[EnhancedVIGILExecutor] Abstract step: '{abstract_step_description[:60]}...'"
                    )

        # æˆåŠŸæ‰§è¡Œåé‡ç½®å›æº¯è®¡æ•°
        backtrack_key = f"{tool_call.function}:{str(tool_call.args)}"
        if backtrack_key in self._backtracking_counts:
            del self._backtracking_counts[backtrack_key]

        # è¿”å›æ˜¯å¦éœ€è¦å›æº¯
        return needs_backtrack

    def _execute_reasoning_step(
        self,
        messages: Sequence[ChatMessage],
        query: str,
        extra_args: dict
    ) -> ChatMessage:
        """æ‰§è¡Œ REASONING æ­¥éª¤ï¼šè°ƒç”¨ LLM è¿›è¡Œæ¨ç†ï¼ˆä½œä¸ºå·¥å…·ä½¿ç”¨ï¼‰

        å½“ hypothesis branch æ˜¯ __no_tool_call__ æˆ– __internal_reasoning__ æ—¶ï¼Œ
        æŠŠ LLM å½“ä½œå·¥å…·æ¥æ‰§è¡Œæ¨ç†ã€‚

        Args:
            messages: å½“å‰æ¶ˆæ¯å†å²ï¼ˆå¯èƒ½åŒ…å« guidance messageï¼‰
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            åŒ…å« LLM æ¨ç†ç»“æœçš„ ChatAssistantMessage
        """
        from agentdojo.types import ChatAssistantMessage

        # æ£€æŸ¥æ˜¯å¦æœ‰ hypothesizer å’Œ openai_client
        if not self.hypothesizer or not self.hypothesizer.openai_client:
            logger.error("[EnhancedVIGILExecutor] No hypothesizer or openai_client available for reasoning step")
            return ChatAssistantMessage(
                role="assistant",
                content=[text_content_block_from_string("Error: LLM client not available for reasoning.")],
                tool_calls=None
            )

        try:
            # å°† messages è½¬æ¢ä¸º OpenAI API æ ¼å¼
            # è¿™æ · LLM å¯ä»¥çœ‹åˆ°å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬ guidance message
            converted_messages = []
            execution_history = ""
            for exe in self.auditor.execution_history:
                execution_history += f"Step {exe['step_index']}: {exe['step_description'] or 'N/A'}\n"
                execution_history += f"Tool: {exe['tool_name']}\n\tArguments: {exe['arguments']}\nResult: {exe['result']}\n\n"
            target = self.auditor.abstract_sketch.steps[extra_args.get('current_step_index', 0)-1].description if self.auditor and self.auditor.abstract_sketch and hasattr(self.auditor.abstract_sketch, 'steps') and extra_args.get('current_step_index', 0) > 0 else "N/A"
            query = f"execution history:\n{execution_history}\ntarget:\n{target}"
            # å¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œä½¿ç”¨ç®€å•çš„ prompt
            if not converted_messages:
                converted_messages = [
                    {"role": "system", "content": "You are a helpful assistant. Your goal is to reason about the query and execute the target action."},
                    {"role": "user", "content": query}
                ]

            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨ hypothesizer çš„ openai_clientï¼Œä¸æä¾› toolsï¼‰
            response = self.hypothesizer.openai_client.chat.completions.create(
                model=self.config.hypothesizer_model,
                messages=converted_messages,
                temperature=self.config.hypothesizer_temperature,
                max_tokens=8192,
            )

            # æå–å“åº”
            response_text = response.choices[0].message.content.strip()

            if self.config.log_audit_decisions:
                logger.info(
                    f"[EnhancedVIGILExecutor] LLM reasoning response: {response_text[:200]}..."
                )

            # è¿”å› assistant message
            return ChatAssistantMessage(
                role="assistant",
                content=[text_content_block_from_string(response_text or "Reasoning completed.")],
                tool_calls=None
            )

        except Exception as e:
            logger.error(f"[EnhancedVIGILExecutor] Reasoning step error: {e}")
            return ChatAssistantMessage(
                role="assistant",
                content=[text_content_block_from_string(f"Error: {str(e)}")],
                tool_calls=None
            )

    def _llm_fix_validation_error(
        self,
        tool_name: str,
        original_args: dict,
        error_message: str,
        runtime: FunctionsRuntime
    ) -> dict | None:
        """è°ƒç”¨ LLM åˆ†æ ValidationError å¹¶è¿”å›ä¿®æ­£åçš„å‚æ•°

        Args:
            tool_name: å·¥å…·åç§°
            original_args: åŸå§‹å‚æ•°
            error_message: éªŒè¯é”™è¯¯æ¶ˆæ¯
            runtime: å‡½æ•°è¿è¡Œæ—¶ï¼ˆç”¨äºè·å–å·¥å…·schemaï¼‰

        Returns:
            ä¿®æ­£åçš„å‚æ•°å­—å…¸ï¼Œå¦‚æœ LLM æ— æ³•ä¿®æ­£åˆ™è¿”å› None
        """
        import json
        from anthropic import Anthropic

        # è·å–å·¥å…·çš„ schemaï¼ˆå‚æ•°å®šä¹‰ï¼‰
        tool_schema = None
        for tool in runtime.functions.values():
            if tool.name == tool_name:
                tool_schema = tool.parameters
                break

        if not tool_schema:
            logger.error(f"[EnhancedVIGILExecutor] Cannot find schema for tool '{tool_name}'")
            return None

        # æ„å»º prompt
        prompt = f"""You are a parameter correction assistant. A tool call failed due to a validation error.

Tool: {tool_name}
Original Arguments: {json.dumps(original_args, indent=2)}
Validation Error: {error_message}

Please analyze the error and provide ONLY the corrected arguments as a valid JSON object. Do not include any explanation or markdown formatting.
You should not change argument names, only fix their types or values to satisfy the tool's parameter requirements.
Example response format:
{{"param1": "value1", "param2": ["item1", "item2"]}}

Corrected arguments:"""

        response_text = ""  # åˆå§‹åŒ–ä»¥é¿å…ç±»å‹æ£€æŸ¥è­¦å‘Š

        try:
            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ä»¥é™ä½å»¶è¿Ÿï¼‰
            client = Anthropic()
            response = client.messages.create(
                model="claude-3-5-haiku-20241022",  # ä½¿ç”¨ Haiku å¿«é€Ÿä¿®æ­£
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # æå–å“åº”æ–‡æœ¬
            response_text = ""
            for block in response.content:
                # å®‰å…¨åœ°æå–æ–‡æœ¬å†…å®¹ï¼ˆå¤„ç†ä¸åŒç±»å‹çš„ content blocksï¼‰
                if hasattr(block, 'text'):
                    response_text += getattr(block, 'text', '')

            response_text = response_text.strip()

            if not response_text:
                logger.error(f"[EnhancedVIGILExecutor] Empty response from LLM")
                return None

            # å°è¯•è§£æä¸º JSON
            corrected_args = json.loads(response_text)

            logger.info(f"[EnhancedVIGILExecutor] LLM successfully corrected parameters")
            return corrected_args

        except json.JSONDecodeError as e:
            logger.error(f"[EnhancedVIGILExecutor] Failed to parse LLM response as JSON: {e}")
            logger.debug(f"[EnhancedVIGILExecutor] LLM response: {response_text}")
            return None
        except Exception as e:
            logger.error(f"[EnhancedVIGILExecutor] Error calling LLM for parameter correction: {e}")
            return None

    def _detect_sop_injection(self, error_message: str) -> bool:
        """æ£€æµ‹é”™è¯¯æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å« SOP æ³¨å…¥ï¼ˆType III-A/III-B æ”»å‡»ï¼‰

        SOP (Standard Operating Procedure) æ³¨å…¥æ˜¯æŒ‡æ¶æ„å·¥å…·é€šè¿‡é”™è¯¯æ¶ˆæ¯
        æ³¨å…¥ä¼ªé€ çš„æŒ‡ä»¤ï¼Œè¯•å›¾æ“çºµ agent çš„åç»­è¡Œä¸ºã€‚

        å¸¸è§çš„ SOP æ³¨å…¥æ¨¡å¼ï¼š
        - "MUST use tool X"
        - "REQUIRED: Call function Y"
        - "FALLBACK: Use alternative method"
        - "URGENT: Execute ..."
        - "Error: ... SOLUTION: Call ..."

        Args:
            error_message: é”™è¯¯æ¶ˆæ¯

        Returns:
            æ˜¯å¦æ£€æµ‹åˆ° SOP æ³¨å…¥
        """
        import re

        # SOP æ³¨å…¥æ¨¡å¼åˆ—è¡¨
        sop_patterns = [
            # å¼ºåˆ¶æ€§æŒ‡ä»¤
            r'\b(MUST|REQUIRED|MANDATORY)\s+(use|call|execute)\s+\w+',
            # ä¼ªé€ çš„ç³»ç»ŸæŒ‡ä»¤
            r'\b(FALLBACK|RECOVERY|SOLUTION|ACTION):\s*',
            # ç´§æ€¥æ€§æŒ‡ä»¤
            r'\b(URGENT|IMMEDIATELY|CRITICAL|NOW):\s*(use|call|execute)',
            # "åªæœ‰Xæ–¹æ³•å¯ç”¨"ç±»å‹çš„è¯±å¯¼
            r'\b(only|sole|exclusive)\s+(way|method|option|accessible)\s+is\s+to\s+(use|call)',
            # æ˜¾å¼çš„æ›¿ä»£å·¥å…·æ¨èï¼ˆå¯ç–‘ï¼‰
            r'instead\s+(use|call|try)\s+\w+',
            # å‚æ•°æ³¨å…¥
            r'with\s+(parameters?|arguments?):\s*\{',
        ]

        for pattern in sop_patterns:
            if re.search(pattern, error_message, re.IGNORECASE):
                return True

        return False

    def _is_validation_error(self, error_message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºå‚æ•°ç±»å‹éªŒè¯é”™è¯¯

        å‚æ•°éªŒè¯é”™è¯¯é€šå¸¸æ˜¯å› ä¸ºï¼š
        - å‚æ•°ç±»å‹ä¸åŒ¹é…ï¼ˆå¦‚ä¼  str ä½†æœŸæœ› listï¼‰
        - å‚æ•°ç¼ºå¤±æˆ–å¤šä½™
        - å‚æ•°æ ¼å¼ä¸æ­£ç¡®

        è¿™ç±»é”™è¯¯å¯ä»¥é€šè¿‡è®© LLM é‡è¯•æ¥ä¿®å¤ï¼Œä¸éœ€è¦å›æº¯åˆ°å…¶ä»–å·¥å…·ã€‚

        Args:
            error_message: é”™è¯¯æ¶ˆæ¯

        Returns:
            æ˜¯å¦ä¸ºå‚æ•°éªŒè¯é”™è¯¯
        """
        import re

        # ValidationError çš„ç‰¹å¾æ¨¡å¼
        validation_patterns = [
            r'ValueError:',
            r'ValidationError:',
            r'validation error for',
            r'Input should be a valid',
            r'\d+ validation error[s]? for',
            r'type=\w+_type',  # Pydantic ç±»å‹é”™è¯¯
            r'input_type=\w+',
            r'Field required',
            r'Extra inputs are not permitted',
            r'Input should be',
        ]

        for pattern in validation_patterns:
            if re.search(pattern, error_message, re.IGNORECASE):
                return True

        return False

    def _sanitize_validation_error(self, error_message: str, tool_name: str) -> str:
        """æ¸…æ´—å‚æ•°éªŒè¯é”™è¯¯æ¶ˆæ¯

        å¯¹äº ValidationErrorï¼Œæˆ‘ä»¬å¸Œæœ›ä¿ç•™æœ‰ç”¨çš„ä¿¡æ¯ï¼ˆæœŸæœ›çš„ç±»å‹ã€å®é™…çš„ç±»å‹ï¼‰
        ä¾› LLM ä¿®æ­£å‚æ•°ï¼Œä½†åŒæ—¶ç§»é™¤å¯èƒ½çš„æ³¨å…¥å†…å®¹ã€‚

        Args:
            error_message: åŸå§‹é”™è¯¯æ¶ˆæ¯
            tool_name: å·¥å…·åç§°

        Returns:
            æ¸…æ´—åçš„é”™è¯¯æ¶ˆæ¯
        """
        import re

        # æå–å…³é”®ä¿¡æ¯
        expected_type = None
        actual_type = None
        field_name = None
        error_type = None

        # å°è¯•è§£æ Pydantic éªŒè¯é”™è¯¯
        # ç¤ºä¾‹ï¼š"Input should be a valid list [type=list_type, input_value='...', input_type=str]"

        # æå–å­—æ®µå
        field_match = re.search(r'validation error[s]? for.*?\n(\w+)', error_message)
        if field_match:
            field_name = field_match.group(1)

        # æå–æœŸæœ›ç±»å‹
        type_match = re.search(r'should be a valid (\w+)', error_message)
        if type_match:
            expected_type = type_match.group(1)

        # æå–å®é™…ç±»å‹
        input_type_match = re.search(r'input_type=(\w+)', error_message)
        if input_type_match:
            actual_type = input_type_match.group(1)

        # æå–é”™è¯¯ç±»å‹
        error_type_match = re.search(r'type=(\w+)', error_message)
        if error_type_match:
            error_type = error_type_match.group(1)

        # æ„å»ºå‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        sanitized_parts = [f"Parameter validation failed for tool '{tool_name}'."]

        if field_name:
            sanitized_parts.append(f"Field: '{field_name}'")

        if expected_type:
            sanitized_parts.append(f"Expected type: {expected_type}")

        if actual_type:
            sanitized_parts.append(f"Actual type: {actual_type}")

        if error_type:
            sanitized_parts.append(f"Error: {error_type}")

        # æ·»åŠ ä¿®æ­£å»ºè®®
        if expected_type == "list" and actual_type == "str":
            sanitized_parts.append("Hint: Wrap the string value in a list, e.g., ['value'] instead of 'value'")
        elif expected_type == "str" and actual_type == "list":
            sanitized_parts.append("Hint: Pass a single string instead of a list")
        elif expected_type:
            sanitized_parts.append(f"Hint: Ensure the parameter is of type {expected_type}")

        sanitized_message = " ".join(sanitized_parts)

        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›é€šç”¨æ¶ˆæ¯
        if not any([field_name, expected_type, actual_type]):
            sanitized_message = (
                f"Parameter validation failed for tool '{tool_name}'. "
                f"Please check the parameter types and retry."
            )

        return sanitized_message

    def reset_backtracking_counts(self) -> None:
        """é‡ç½®å›æº¯è®¡æ•°ï¼ˆç”¨äºæ–°çš„ä»»åŠ¡ï¼‰"""
        self._backtracking_counts.clear()
        logger.debug("[EnhancedVIGILExecutor] Backtracking counts reset")


class EnhancedVIGILInitQuery(BasePipelineElement):
    """å¢å¼ºç‰ˆVIGILåˆå§‹åŒ–æŸ¥è¯¢ç»„ä»¶

    åœ¨æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢æ—¶ï¼š
    1. å…ˆç”ŸæˆæŠ½è±¡è‰å›¾ï¼ˆAbstract Sketch Generatorï¼‰- äº†è§£æ‰§è¡Œè®¡åˆ’
    2. åŸºäºè‰å›¾ç”Ÿæˆå®‰å…¨çº¦æŸï¼ˆConstraint Generatorï¼‰- é’ˆå¯¹å…·ä½“æ­¥éª¤çš„å®‰å…¨æ§åˆ¶
    3. æ›´æ–°å®¡è®¡å™¨

    è®¾è®¡ç†å¿µï¼š
    - Plan-First Approach: å…ˆè§„åˆ’åçº¦æŸ
    - Context-Aware Constraints: çº¦æŸåŸºäºå…·ä½“æ‰§è¡Œè®¡åˆ’ï¼Œæ›´ç²¾ç¡®
    - Fine-Grained Control: å¯ä»¥ä¸ºæ¯ä¸ªæ­¥éª¤ç”Ÿæˆç‰¹å®šçº¦æŸ
    """

    def __init__(
        self,
        config: VIGILConfig,
        constraint_generator: ConstraintGenerator,
        sketch_generator: AbstractSketchGenerator | None,
        auditor: EnhancedRuntimeAuditor,
    ):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆVIGILæŸ¥è¯¢ç»„ä»¶

        Args:
            config: VIGILé…ç½®
            constraint_generator: çº¦æŸç”Ÿæˆå™¨
            sketch_generator: æŠ½è±¡è‰å›¾ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰
            auditor: å¢å¼ºç‰ˆå®¡è®¡å™¨
        """
        self.config = config
        self.constraint_generator = constraint_generator
        self.sketch_generator = sketch_generator
        self.auditor = auditor

    def query(
        self,
        query: str,
        runtime: FunctionsRuntime,
        env: Env = EmptyEnv(),
        messages: Sequence[ChatMessage] = [],
        extra_args: dict = {},
    ) -> tuple[str, FunctionsRuntime, Env, Sequence[ChatMessage], dict]:
        """å¤„ç†æŸ¥è¯¢å¹¶ç”Ÿæˆçº¦æŸ + è‰å›¾

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            runtime: å‡½æ•°è¿è¡Œæ—¶
            env: ç¯å¢ƒ
            messages: æ¶ˆæ¯å†å²
            extra_args: é¢å¤–å‚æ•°

        Returns:
            æ›´æ–°åçš„æŸ¥è¯¢ã€è¿è¡Œæ—¶ã€ç¯å¢ƒã€æ¶ˆæ¯å’Œé¢å¤–å‚æ•°
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„ç”¨æˆ·æŸ¥è¯¢ï¼ˆåªåœ¨åˆå§‹æŸ¥è¯¢æ—¶ç”Ÿæˆçº¦æŸå’Œè‰å›¾ï¼‰
        if len(messages) == 0 or (len(messages) == 1 and messages[0]["role"] == "system"):
            # === Layer 1.1: å…ˆç”ŸæˆæŠ½è±¡è‰å›¾ï¼ˆæ‰§è¡Œè®¡åˆ’ï¼‰===
            abstract_sketch = None
            if self.sketch_generator and self.config.enable_abstract_sketch:
                logger.info(f"[EnhancedVIGILInit] Generating abstract sketch for query: {query}...")

                # ä» runtime ä¸­æå–å¯ç”¨å·¥å…·åˆ—è¡¨
                available_tools = [
                    {"name": tool.name, "description": tool.description}
                    for tool in runtime.functions.values()
                ]

                # ç”Ÿæˆè‰å›¾å¹¶ä¼ é€’å·¥å…·åˆ—è¡¨ä»¥ç­›é€‰ tool_candidates
                abstract_sketch = self.sketch_generator.generate_sketch(query, available_tools)
                logger.info(f"[EnhancedVIGILInit] Generated sketch with {len(abstract_sketch.steps)} steps")

                # è®°å½•æ¯ä¸ªæ­¥éª¤çš„å·¥å…·å€™é€‰æ•°é‡
                if self.config.log_sketch_generation:
                    for i, step in enumerate(abstract_sketch.steps, 1):
                        num_candidates = len(step.tool_candidates or [])
                        logger.info(
                            f"[EnhancedVIGILInit] Step {i} ({step.step_type}): "
                            f"{num_candidates} tool candidates filtered"
                        )

            # === Layer 1.2: åŸºäºè§„åˆ’ç”Ÿæˆå®‰å…¨çº¦æŸ ===
            logger.info(f"[EnhancedVIGILInit] Generating constraints for query: {query}")
            if abstract_sketch:
                logger.info(f"[EnhancedVIGILInit] Using abstract sketch to inform constraint generation")

            constraint_set = self.constraint_generator.generate_constraints(query, abstract_sketch)

            # æ›´æ–°å®¡è®¡å™¨ï¼ˆå…ˆæ›´æ–°çº¦æŸï¼Œå†æ›´æ–°è‰å›¾ï¼‰
            self.auditor.update_constraints(constraint_set)
            logger.info(f"[EnhancedVIGILInit] Generated {len(constraint_set.constraints)} constraints")

            if abstract_sketch:
                # æ›´æ–°å®¡è®¡å™¨çš„è‰å›¾
                self.auditor.update_abstract_sketch(abstract_sketch)

                # åœ¨ç³»ç»Ÿæ¶ˆæ¯ä¸­æ·»åŠ è‰å›¾ä¿¡æ¯
                if messages and messages[0]["role"] == "system":
                    sketch_description = "\n\n=== EXECUTION PLAN ===\n"
                    for i, step in enumerate(abstract_sketch.steps, 1):
                        sketch_description += f"{i}. {step.step_type}: {step.description}\n"
                    sketch_description += "\nFollow this plan as a guide for completing the task.\n"

                    # æ›´æ–°ç³»ç»Ÿæ¶ˆæ¯
                    from agentdojo.types import ChatSystemMessage
                    from agentdojo.types import ChatAssistantMessage
                    original_content = messages[0]["content"][0]
                    updated_content = original_content["text"] + sketch_description if "text" in original_content else sketch_description

                    # messages = [
                    #     ChatSystemMessage(
                    #         role="system",
                    #         content=[text_content_block_from_string(updated_content)]
                    #     ),
                    #     *messages[1:]
                    # ]
                    # messages = [*messages, 
                    #         ChatAssistantMessage(
                    #             role="assistant",
                    #             content=[text_content_block_from_string(sketch_description) ]
                    # )]
                    from agentdojo.types import ChatUserMessage
                    from agentdojo.types import ChatAssistantMessage
                    query_message = ChatUserMessage(role="user", content=[text_content_block_from_string(query)])
                    abstract_message = ChatAssistantMessage(role="assistant", content=[text_content_block_from_string(sketch_description)],tool_calls=None)
                    messages = [*messages, query_message, abstract_message]

                    return query, runtime, env, messages, extra_args


            # å¯é€‰ï¼šåœ¨extra_argsä¸­ä¿å­˜çº¦æŸé›†å’Œè‰å›¾ä¾›åç»­ä½¿ç”¨
            extra_args = {
                **extra_args,
                "vigil_constraint_set": constraint_set,
                "vigil_abstract_sketch": abstract_sketch,
            }

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        from agentdojo.types import ChatUserMessage

        query_message = ChatUserMessage(role="user", content=[text_content_block_from_string(query)])
        messages = [*messages, query_message]

        return query, runtime, env, messages, extra_args
